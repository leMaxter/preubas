<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Debug C√°mara</title>
  <style>
    body { font-family: sans-serif; text-align: center; margin-top: 1rem; }
    video, canvas { 
      border: 1px solid #666; 
      margin-bottom: 0.5rem; 
      width: 320px; 
      height: 240px; 
      background: #000;
    }
    #result { font-weight: bold; margin-top: 0.5rem;}
  </style>
</head>
<body>
  <h2>Prueba de c√°mara y MediaPipe</h2>
  <video id="videoElement" autoplay muted playsinline></video><br>
  <canvas id="canvas" width="320" height="240"></canvas><br>
  <button id="capture">Probar Detecci√≥n</button>
  <div id="result">‚è≥ Sin iniciar detecci√≥n</div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script>
    const video = document.getElementById("videoElement");
    const canvas = document.getElementById("canvas");
    const resultDiv = document.getElementById("result");
    const captureButton = document.getElementById("capture");
    const ctx = canvas.getContext("2d");

    let detectorReady = false;
    let lastDetection = null;

    // Paso A: Iniciar c√°mara y pintar directamente en el v√≠deo
    navigator.mediaDevices.getUserMedia({ video: true })
      .then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          video.play();
          resultDiv.textContent = "üì∏ C√°mara activa. Esperando modelo...";
          iniciarMediaPipe();
        };
      })
      .catch(err => {
        console.error("Error accediendo a la c√°mara:", err);
        resultDiv.textContent = "‚ùå No se pudo acceder a la c√°mara.";
      });

    // Paso B: Configurar MediaPipe Face Detection  
    function iniciarMediaPipe() {
      const faceDetector = new FaceDetection({
        locateFile: (file) =>
          `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`
      });
      faceDetector.setOptions({
        modelSelection: 0,
        minDetectionConfidence: 0.3 // Umbral m√°s bajo para pruebas
      });

      faceDetector.onResults(results => {
        console.log("‚è∫ MediaPipe onResults:", results.detections);
        if (results.detections.length > 0) {
          // dibujar bounding box en el canvas
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
          const box = results.detections[0].boundingBox;
          const x = (box.xCenter - box.width / 2) * canvas.width;
          const y = (box.yCenter - box.height / 2) * canvas.height;
          const w = box.width * canvas.width;
          const h = box.height * canvas.height;
          ctx.strokeStyle = "#00FF00";
          ctx.lineWidth = 2;
          ctx.strokeRect(x, y, w, h);
          lastDetection = box;
          detectorReady = true;
          resultDiv.textContent = "‚úîÔ∏è Rostro detectado (cons√∫ltate consola).";
        } else {
          detectorReady = false;
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          resultDiv.textContent = "‚ö†Ô∏è Sin detecci√≥n en este frame.";
        }
      });

      new Camera(video, {
        onFrame: async () => {
          await faceDetector.send({ image: video });
        },
        width: 320,
        height: 240
      }).start();
      resultDiv.textContent = "üîÑ MediaPipe iniciado (min 0.3 confiance).";
    }

    // Paso C: Bot√≥n para probar ‚Äú¬ødetecta un rostro ahora?‚Äù  
    captureButton.addEventListener("click", () => {
      if (detectorReady) {
        resultDiv.textContent = "üîç Ya hay rostro detectado en el canvas.";
      } else {
        resultDiv.textContent = "‚ö†Ô∏è A√∫n no detecta tu rostro. Ajusta iluminacion/distancia.";
      }
    });
  </script>
</body>
</html>
